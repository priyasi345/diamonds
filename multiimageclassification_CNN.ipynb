{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled",
      "provenance": [],
      "authorship_tag": "ABX9TyO5e2wfe77CJAbu3LCGEzQT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyasi345/diamonds/blob/master/multiimageclassification_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ghd8CqldNMM5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2#reading and resizing                 \n",
        "import numpy as np#arrays         \n",
        "import os#dealing with directories                  \n",
        "from random import shuffle #to shuffle data\n",
        "from tqdm import tqdm#loop progress bar  \n",
        "from sklearn.metrics import roc_auc_score    \n",
        "import matplotlib.pyplot as plt # for visualizations\n",
        "import tensorflow as tf # For tensor operations\n",
        "import pandas as pd # for manipulating data\n",
        "import zipfile\n",
        "import os, sys"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRcTHGTaOQhi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dad6148e-e7d1-4652-a290-e451a256f8df"
      },
      "source": [
        "IMG_SIZE = 80\n",
        "\n",
        "epochs = 5\n",
        "step_size = 8\n",
        "IMG_SIZE_ALEXNET = 227\n",
        "validating_size = 40\n",
        "nodes_fc1 = 4096\n",
        "nodes_fc2 = 4096\n",
        "output_classes = 4\n",
        "\n",
        "TRAIN_DIR = os.getcwd()\n",
        "\n",
        "#Current working directory\n",
        "\n",
        "print(TRAIN_DIR) # current working directory"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brRlcdJgQVw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Unzipping file\n",
        "with zipfile.ZipFile(\"datasets.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall()\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB_733rQsJiT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Reading .npy files\n",
        "train_data = np.load(os.path.join(os.getcwd(), 'datasets' ,'train_data_mc.npy'), allow_pickle=True)\n",
        "test_data = np.load(os.path.join(os.getcwd(), 'datasets' ,'test_data_mc.npy'), allow_pickle=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c00ylMftOVYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#In order to implement ALEXNET, we are resizing them to (227,227,3)\n",
        "for i in range(len(train_data)):\n",
        "    train_data[i][0] = cv2.resize(train_data[i][0],(IMG_SIZE_ALEXNET,IMG_SIZE_ALEXNET))\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "    test_data[i][0] = cv2.resize(test_data[i][0],(IMG_SIZE_ALEXNET,IMG_SIZE_ALEXNET))\n",
        "\n",
        "train = train_data[:4800]\n",
        "cv = train_data[4800:]\n",
        "\n",
        "X = np.array([i[0] for i in train]).reshape(-1,IMG_SIZE_ALEXNET,IMG_SIZE_ALEXNET,3)\n",
        "Y = np.array([i[1] for i in train])\n",
        "\n",
        "cv_x = np.array([i[0] for i in cv]).reshape(-1,IMG_SIZE_ALEXNET,IMG_SIZE_ALEXNET,3)\n",
        "cv_y = np.array([i[1] for i in cv])\n",
        "test_x = np.array([i[0] for i in test_data]).reshape(-1,IMG_SIZE_ALEXNET,IMG_SIZE_ALEXNET,3)\n",
        "test_y = np.array([i[1] for i in test_data])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "avkqvTbmpU7j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "acdbb2ac-61ba-4efe-b92d-05d6030102e8"
      },
      "source": [
        "print(X.shape)\n",
        "\n",
        "print(Y.shape)\n",
        "\n",
        "print(cv_x.shape)\n",
        "\n",
        "print(test_x.shape)\n",
        "\n",
        "steps = len(train)\n",
        "print(steps)\n",
        "remaining = steps % step_size"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4800, 227, 227, 3)\n",
            "(4800, 4)\n",
            "(400, 227, 227, 3)\n",
            "(1267, 227, 227, 3)\n",
            "4800\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EpO16kutcQO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 962
        },
        "outputId": "493a4881-dda1-4809-8f7c-cef24ef030ad"
      },
      "source": [
        "!pip install tensorflow==1.15.0"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 46kB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.9.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.18.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.2.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.29.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.0.8)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 52.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.8.1)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 54.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.2.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (0.34.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15.0) (1.12.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15.0) (2.10.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.2.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (47.3.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (1.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15.0) (3.1.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=8f3c11a441ba10ad38e96fe97572b75e9688f9da4a85b54817d7c2fb5a071eca\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.10.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.2.2\n",
            "    Uninstalling tensorboard-2.2.2:\n",
            "      Successfully uninstalled tensorboard-2.2.2\n",
            "  Found existing installation: tensorflow-estimator 2.2.0\n",
            "    Uninstalling tensorflow-estimator-2.2.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.2.0\n",
            "  Found existing installation: tensorflow 2.2.0\n",
            "    Uninstalling tensorflow-2.2.0:\n",
            "      Successfully uninstalled tensorflow-2.2.0\n",
            "Successfully installed gast-0.2.2 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "gast",
                  "tensorboard",
                  "tensorflow"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHLMy6ZCpWxI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.python.framework import ops\n",
        "import tensorflow as tf\n",
        "ops.reset_default_graph()\n",
        "\n",
        "\n",
        "\n",
        "#Defining Placeholders\n",
        "x = tf.placeholder(tf.float32,shape=[None,IMG_SIZE_ALEXNET,IMG_SIZE_ALEXNET,3])\n",
        "y_true = tf.placeholder(tf.float32,shape=[None,output_classes])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYuejJsjpZiG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "060e55e1-8c01-4cbc-ea6a-084e49615300"
      },
      "source": [
        "\n",
        "##CONVOLUTION LAYER 1\n",
        "#Weights for layer 1\n",
        "w_1 = tf.Variable(tf.truncated_normal([11,11,3,96], stddev=0.01))\n",
        "#Bias for layer 1\n",
        "b_1 = tf.Variable(tf.constant(0.0, shape=[[11,11,3,96][3]]))\n",
        "#Applying convolution\n",
        "c_1 = tf.nn.conv2d(x, w_1,strides=[1, 4, 4, 1], padding='VALID')\n",
        "#Adding bias\n",
        "c_1 = c_1 + b_1\n",
        "#Applying RELU\n",
        "c_1 = tf.nn.relu(c_1)\n",
        "print(c_1)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Relu:0\", shape=(?, 55, 55, 96), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vq4Gu6OmpZ9x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "72a0bb96-2bc2-4947-c0d9-261304278079"
      },
      "source": [
        "\n",
        "##POOLING LAYER1\n",
        "p_1 = tf.nn.max_pool(c_1, ksize=[1, 3, 3, 1],strides=[1, 2, 2, 1], padding='VALID')\n",
        "print(p_1)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"MaxPool:0\", shape=(?, 27, 27, 96), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-0FK2Qopc5c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b25dab72-e9f5-40b6-a68e-021c37204be1"
      },
      "source": [
        "\n",
        "##CONVOLUTION LAYER 2\n",
        "#Weights for layer 2\n",
        "w_2 = tf.Variable(tf.truncated_normal([5,5,96,256], stddev=0.01))\n",
        "#Bias for layer 2\n",
        "b_2 = tf.Variable(tf.constant(1.0, shape=[[5,5,96,256][3]]))\n",
        "#Applying convolution\n",
        "c_2 = tf.nn.conv2d(p_1, w_2,strides=[1, 1, 1, 1], padding='SAME')\n",
        "#Adding bias\n",
        "c_2 = c_2 + b_2\n",
        "#Applying RELU\n",
        "c_2 = tf.nn.relu(c_2)\n",
        "\n",
        "print(c_2)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Relu_1:0\", shape=(?, 27, 27, 256), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRAbMmwWpeoP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1eae7b6b-13f3-438c-9256-b286d036c63a"
      },
      "source": [
        "\n",
        "##POOLING LAYER2\n",
        "p_2 = tf.nn.max_pool(c_2, ksize=[1, 3, 3, 1],strides=[1, 2, 2, 1], padding='VALID')\n",
        "print(p_2)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"MaxPool_1:0\", shape=(?, 13, 13, 256), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nb6nRjUPpgnZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "21516c1a-4faa-461b-c470-ca0a148d8d72"
      },
      "source": [
        "\n",
        "##CONVOLUTION LAYER 3\n",
        "#Weights for layer 3\n",
        "w_3 = tf.Variable(tf.truncated_normal([3, 3, 256, 384], stddev=0.01))\n",
        "#Bias for layer 3\n",
        "b_3 = tf.Variable(tf.constant(0.0, shape=[[3, 3, 256, 384][3]]))\n",
        "#Applying convolution\n",
        "c_3 = tf.nn.conv2d(p_2, w_3,strides=[1, 1, 1, 1], padding='SAME')\n",
        "#Adding bias\n",
        "c_3 = c_3 + b_3\n",
        "#Applying RELU\n",
        "c_3 = tf.nn.relu(c_3)\n",
        "\n",
        "print(c_3)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Relu_2:0\", shape=(?, 13, 13, 384), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0egYe0UPpjDz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e5227b40-d64e-42a1-e7e5-57764a255fc1"
      },
      "source": [
        "##CONVOLUTION LAYER 4\n",
        "#Weights for layer 4\n",
        "w_4 = tf.Variable(tf.truncated_normal([3, 3, 384, 384], stddev=0.01))\n",
        "#Bias for layer 4\n",
        "b_4 = tf.Variable(tf.constant(0.0, shape=[[3, 3, 384, 384][3]]))\n",
        "#Applying convolution\n",
        "c_4 = tf.nn.conv2d(c_3, w_4,strides=[1, 1, 1, 1], padding='SAME')\n",
        "#Adding bias\n",
        "c_4 = c_4 + b_4\n",
        "#Applying RELU\n",
        "c_4 = tf.nn.relu(c_4)\n",
        "\n",
        "print(c_4)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Relu_3:0\", shape=(?, 13, 13, 384), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5oLsHPkplD2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "eb0d5d8f-15f4-4436-d33c-0c9f79c186f3"
      },
      "source": [
        "##CONVOLUTION LAYER 5\n",
        "#Weights for layer 5\n",
        "w_5 = tf.Variable(tf.truncated_normal([3, 3, 384, 256], stddev=0.01))\n",
        "#Bias for layer 5\n",
        "b_5 = tf.Variable(tf.constant(0.0, shape=[[3, 3, 384, 256][3]]))\n",
        "#Applying convolution\n",
        "c_5 = tf.nn.conv2d(c_4, w_5,strides=[1, 1, 1, 1], padding='SAME')\n",
        "#Adding bias\n",
        "c_5 = c_5 + b_5\n",
        "#Applying RELU\n",
        "c_5 = tf.nn.relu(c_5)\n",
        "\n",
        "print(c_5)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Relu_4:0\", shape=(?, 13, 13, 256), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWG2ZovPpnvR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "54ce24d0-662c-4d6c-9d2e-f603c862b1c9"
      },
      "source": [
        "##POOLING LAYER3\n",
        "p_3 = tf.nn.max_pool(c_5, ksize=[1, 3, 3, 1],strides=[1, 2, 2, 1], padding='VALID')\n",
        "print(p_3)\n",
        "\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"MaxPool_2:0\", shape=(?, 6, 6, 256), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nFx3t_HhpsFL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7887bb9d-178b-450e-9b0d-afb7aca5a390"
      },
      "source": [
        "\n",
        "#Flattening\n",
        "flattened = tf.reshape(p_3,[-1,6*6*256])\n",
        "print(flattened)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Reshape:0\", shape=(?, 9216), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR09GKnUpuAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Fully Connected Layer 1\n",
        "#Getting input nodes in FC layer 1\n",
        "input_size = int( flattened.get_shape()[1] )\n",
        "#Weights for FC Layer 1\n",
        "w1_fc = tf.Variable(tf.truncated_normal([input_size, nodes_fc1], stddev=0.01))\n",
        "#Bias for FC Layer 1\n",
        "b1_fc = tf.Variable( tf.constant(1.0, shape=[nodes_fc1] ) )\n",
        "#Summing Matrix calculations and bias\n",
        "s_fc1 = tf.matmul(flattened, w1_fc) + b1_fc\n",
        "#Applying RELU\n",
        "s_fc1 = tf.nn.relu(s_fc1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bxsdEpe8pwVj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "3c9af5e8-b1df-4e15-c337-f0977b987287"
      },
      "source": [
        "\n",
        "#Dropout Layer 1\n",
        "hold_prob1 = tf.placeholder(tf.float32)\n",
        "s_fc1 = tf.nn.dropout(s_fc1,keep_prob=hold_prob1)\n",
        "print(s_fc1)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-19-cc16b396ae7b>:4: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "Tensor(\"dropout/mul_1:0\", shape=(?, 4096), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPWqT7fIpyeW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "775f6b9f-6cb4-43a1-88f8-7ea930aeab1a"
      },
      "source": [
        "\n",
        "##Fully Connected Layer 2\n",
        "#Weights for FC Layer 2\n",
        "w2_fc = tf.Variable(tf.truncated_normal([nodes_fc1, nodes_fc2], stddev=0.01))\n",
        "#Bias for FC Layer 2\n",
        "b2_fc = tf.Variable( tf.constant(1.0, shape=[nodes_fc2] ) )\n",
        "#Summing Matrix calculations and bias\n",
        "s_fc2 = tf.matmul(s_fc1, w2_fc) + b2_fc\n",
        "#Applying RELU\n",
        "s_fc2 = tf.nn.relu(s_fc2)\n",
        "print(s_fc2)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Relu_6:0\", shape=(?, 4096), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOulNtV7p0iS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Dropout Layer 2\n",
        "hold_prob2 = tf.placeholder(tf.float32)\n",
        "s_fc2 = tf.nn.dropout(s_fc2,keep_prob=hold_prob1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Y1A8BOtp2_8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "52bbbcbc-3d30-4af1-dfa6-7d921a981722"
      },
      "source": [
        "##Fully Connected Layer 3\n",
        "#Weights for FC Layer 3\n",
        "w3_fc = tf.Variable(tf.truncated_normal([nodes_fc2,output_classes], stddev=0.01))\n",
        "#Bias for FC Layer 3b3_fc = tf.Variable( tf.constant(1.0, shape=[output_classes] ) )\n",
        "b3_fc = tf.Variable( tf.constant(1.0, shape=[output_classes] ) )\n",
        "#Summing Matrix calculations and bias\n",
        "y_pred = tf.matmul(s_fc2, w3_fc) + b3_fc\n",
        "#Applying RELU\n",
        "print(y_pred)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"add_7:0\", shape=(?, 4), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OuPJH88sp5AP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Defining loss function\n",
        "\n",
        "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_true,logits=y_pred))\n",
        "\n",
        "#Defining objective\n",
        "train = tf.train.AdamOptimizer(learning_rate=0.00001).minimize(cross_entropy)\n",
        "\n",
        "#Defining Accuracy\n",
        "matches = tf.equal(tf.argmax(y_pred,1),tf.argmax(y_true,1))\n",
        "acc = tf.reduce_mean(tf.cast(matches,tf.float32))\n",
        "\n",
        "#Initializing weights\n",
        "init = tf.global_variables_initializer()"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XFccpmn7p7ib",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Starting Empty lists to keep results\n",
        "acc_list = []\n",
        "auc_list = []\n",
        "loss_list = []\n",
        "saver = tf.train.Saver()"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wITDL132-Q1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#GPU settings\n",
        "config = tf.ConfigProto(allow_soft_placement=True)\n",
        "config.gpu_options.allow_growth = True\n",
        "config.gpu_options.allocator_type = 'BFC'\n",
        "with tf.Session(config=config) as sess:\n",
        "    sess.run(init)\n",
        "    for i in range(epochs):\n",
        "        for j in range(0,steps-remaining,step_size):\n",
        "            #Feeding step_size-amount data with 0.5 keeping probabilities on DROPOUT LAYERS\n",
        "            _,c = sess.run([train,cross_entropy],\n",
        "\t\t\tfeed_dict={x:X[j:j+step_size] , y_true:Y[j:j+step_size],hold_prob1:0.5,hold_prob2:0.5})\n",
        "        \n",
        "        \n",
        "\t\t#Writing for loop to calculate test statistics. GTX 1050 isn't able to calculate all test data.\n",
        "        cv_auc_list = []\n",
        "        cv_acc_list = []\n",
        "        cv_loss_list = []\n",
        "        for v in range(0,len(cv_x)-int(len(cv_x) % validating_size),validating_size):\n",
        "            acc_on_cv,loss_on_cv,preds = sess.run([acc,cross_entropy,tf.nn.softmax(y_pred)],\n",
        "\t\t\tfeed_dict={x:cv_x[v:v+validating_size] ,y_true:cv_y[v:v+validating_size] ,hold_prob1:1.0,hold_prob2:1.0})\n",
        "\t\t\t\n",
        "            auc_on_cv = roc_auc_score(cv_y[v:v+validating_size],preds)\n",
        "            cv_acc_list.append(acc_on_cv)\n",
        "            cv_auc_list.append(auc_on_cv)\n",
        "            cv_loss_list.append(loss_on_cv)\n",
        "        acc_cv_ = round(np.mean(cv_acc_list),5)\n",
        "        auc_cv_ = round(np.mean(cv_auc_list),5)\n",
        "        loss_cv_ = round(np.mean(cv_loss_list),5)\n",
        "        acc_list.append(acc_cv_)\n",
        "        auc_list.append(auc_cv_)\n",
        "        loss_list.append(loss_cv_)\n",
        "        print(\"Epoch:\",i,\"Accuracy:\",acc_cv_,\"Loss:\",loss_cv_ ,\"AUC:\",auc_cv_)\n",
        "    \n",
        "    test_auc_list = []\n",
        "    test_acc_list = []\n",
        "    test_loss_list = []\n",
        "    for v in range(0,len(test_x)-int(len(test_x) % validating_size),validating_size):\n",
        "        acc_on_test,loss_on_test,preds = sess.run([acc,cross_entropy,tf.nn.softmax(y_pred)],\n",
        "\t\tfeed_dict={x:test_x[v:v+validating_size] ,y_true:test_y[v:v+validating_size] ,hold_prob1:1.0,hold_prob2:1.0})\n",
        "        \n",
        "        auc_on_test = roc_auc_score(test_y[v:v+validating_size],preds)\n",
        "        test_acc_list.append(acc_on_test)\n",
        "        test_auc_list.append(auc_on_test)\n",
        "        test_loss_list.append(loss_on_test)\n",
        "    saver.save(sess, os.path.join(os.getcwd(),\"CNN_MC.ckpt\"))\n",
        "    test_acc_ = round(np.mean(test_acc_list),5)\n",
        "    test_auc_ = round(np.mean(test_auc_list),5)\n",
        "    test_loss_ = round(np.mean(test_loss_list),5)\n",
        "    print(\"Test Results are below:\")\n",
        "    print(\"Accuracy:\",test_acc_,\"Loss:\",test_loss_,\"AUC:\",test_auc_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EYwU83McqGAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "f,ax=plt.subplots(1,3,figsize=(12,3))\n",
        "pd.Series(acc_list).plot(kind='line',title='Accuracy on CV data',ax=ax[0])\n",
        "pd.Series(loss_list).plot(kind='line',figsize=(12,7),title='Loss on CV data',ax=ax[1])\n",
        "pd.Series(auc_list).plot(kind='line',figsize=(12,7),title='AUC on CV data',ax=ax[2])\n",
        "plt.subplots_adjust(wspace=0.8)\n",
        "ax[0].set_title('Accuracy on CV data')\n",
        "ax[1].set_title('Loss on CV data')\n",
        "ax[2].set_title('AUC on CV data')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mj1N6wRRqIf0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Restoring a pretrained\n",
        "with tf.Session() as session:\n",
        "    saver.restore(session, \"CNN_MC.ckpt\")\n",
        "    print(\"Model restored.\") \n",
        "    print('Initialized')\n",
        "    k = session.run([tf.nn.softmax(y_pred)], feed_dict={x:test_x[0:64] , hold_prob1:1,hold_prob2:1})\n",
        "\n",
        "print(np.array(k).shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eX2nCoNqJF8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#Reshaping k\n",
        "k = np.array(k).reshape(64,output_classes)\n",
        "\n",
        "print(k[0])\n",
        "\n",
        "pred_labels = []\n",
        "\n",
        "for i in range(64):\n",
        "    r = np.round(k[i],3).argmax()\n",
        "    if r ==0 : pred_labels.append(\"chair\")\n",
        "    elif r ==1: pred_labels.append(\"kitchen\")\n",
        "    elif r ==2: pred_labels.append(\"knife\")\n",
        "    elif r ==3: pred_labels.append(\"saucepan\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1D0pZmmqMcT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Multiple images parameters\n",
        "w=80\n",
        "h=80\n",
        "columns = 8\n",
        "rows = 8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5F0GkgdqMua",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#First 64 images\n",
        "images = test_x[:64]\n",
        "\n",
        "print(images.shape)\n",
        "\n",
        "fig = plt.figure(figsize=(20, 20))\n",
        "for m in range(1, columns*rows +1):\n",
        "    img = images[m-1].reshape([IMG_SIZE_ALEXNET, IMG_SIZE_ALEXNET, 3])\n",
        "    fig.add_subplot(rows, columns, m)\n",
        "    plt.imshow(img)\n",
        "    plt.title(\"Pred: \" + pred_labels[m-1])\n",
        "    plt.axis('off')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjLZknx8sHif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}